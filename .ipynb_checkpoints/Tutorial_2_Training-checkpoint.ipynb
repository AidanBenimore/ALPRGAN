{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utilities.io import DataLoader\n",
    "from Utilities.lossMetric import *\n",
    "from Utilities.trainVal import MinMaxGame\n",
    "from Models.RRDBNet import RRDBNet\n",
    "from Models.GAN import Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def resize_images(input_dir, output_dir, size):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Iterate over each file in the input directory\n",
    "    for filename in os.listdir(input_dir):\n",
    "        # Check if the file is an image (jpg or png)\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            # Open the image and convert to RGB mode\n",
    "            img = Image.open(os.path.join(input_dir, filename)).convert('RGB')\n",
    "            # Resize the image using bicubic interpolation\n",
    "            img = img.resize(size, Image.BICUBIC)\n",
    "            # Define the new filename with .jpg extension\n",
    "            new_filename = os.path.splitext(filename)[0] + '.jpg'\n",
    "            # Save the resized image to the output directory in JPG format\n",
    "            img.save(os.path.join(output_dir, new_filename), format='JPEG')\n",
    "\n",
    "# Example usage:\n",
    "# Resize high resolution images to 512x512\n",
    "# resize_images('dataset/train/high_res', 'dataset/train/high_res_resized', (512, 512))\n",
    "# resize_images('dataset/test/high_res', 'dataset/test/high_res_resized', (512, 512))\n",
    "\n",
    "# Resize low resolution images to 192x96\n",
    "resize_images('dataset/train/low_res', 'dataset/train/low_res_resized', (192, 96))\n",
    "# resize_images('dataset/test/low_res', 'dataset/test/low_res_resized', (128, 128))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the training dataset\n",
    "I used the Chinese City Parking Dataset for this project. Please download the dataset from https://github.com/detectRecog/CCPD  \n",
    "Before loading the dataset, it is critical that you run the preprocessing script (preprocess.py) first!!!   \n",
    "` \n",
    "python preprocess.py 5 PATH_TO_UNZIPPED_DATA PATH_TO_OUTPUT_DIR\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "PATH = 'D:\\\\Super Resolution\\\\dataset\\\\train\\\\low_res_resized' # only use images with shape 192 by 96 for training\n",
    "files = glob.glob(PATH + '/*.jpg') * 3  # data augmentation, same image with different brightness and contrast\n",
    "np.random.shuffle(files)\n",
    "train, val = files[:int(len(files)*0.8)], files[int(len(files)*0.8):]\n",
    "loader = DataLoader()\n",
    "trainData = DataLoader().load(train, batchSize=16)\n",
    "valData = DataLoader().load(val, batchSize=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Super Resolution\\sr\\lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "discriminator = Discriminator()\n",
    "extractor = buildExtractor()\n",
    "generator = RRDBNet(blockNum=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  It's a good idea to pretrain the generator model before the min-max game - Reference: https://arxiv.org/abs/1701.00160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1942s\u001b[0m 6s/step - loss: 1.2076 - psnr: 11.4990 - ssim: 0.2554 - val_loss: 0.7621 - val_psnr: 13.6752 - val_ssim: 0.3581\n"
     ]
    }
   ],
   "source": [
    "# a simple custom loss function that combines MAE loss with VGG loss, as defined in the SRGAN paper\n",
    "def contentLoss(y_true, y_pred):\n",
    "    featurePred = extractor(y_pred)\n",
    "    feature = extractor(y_true)\n",
    "    mae = tf.reduce_mean(tfk.losses.mae(y_true, y_pred))\n",
    "    return 0.1*tf.reduce_mean(tfk.losses.mse(featurePred, feature)) + mae\n",
    "\n",
    "optimizer = tfk.optimizers.Adam(learning_rate=1e-3)\n",
    "generator.compile(loss=contentLoss, optimizer=optimizer, metrics=[psnr, ssim])\n",
    "# epoch is set to 1 for demonstration purpose. In practice I found 20 is a good number\n",
    "# When the model reaches PSNR=20/ssim=0.65, we can start the min-max game\n",
    "history = generator.fit(x=trainData, validation_data=valData, epochs=1, steps_per_epoch=300, validation_steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative adverserial network training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.3-py3-none-any.whl (139 kB)\n",
      "     -------------------------------------- 139.4/139.4 KB 1.4 MB/s eta 0:00:00\n",
      "Collecting widgetsnbextension~=4.0.11\n",
      "  Downloading widgetsnbextension-4.0.11-py3-none-any.whl (2.3 MB)\n",
      "     ---------------------------------------- 2.3/2.3 MB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: ipython>=6.1.0 in d:\\super resolution\\sr\\lib\\site-packages (from ipywidgets) (8.18.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in d:\\super resolution\\sr\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting jupyterlab-widgets~=3.0.11\n",
      "  Downloading jupyterlab_widgets-3.0.11-py3-none-any.whl (214 kB)\n",
      "     -------------------------------------- 214.4/214.4 KB 6.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: comm>=0.1.3 in d:\\super resolution\\sr\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: stack-data in d:\\super resolution\\sr\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: colorama in d:\\super resolution\\sr\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in d:\\super resolution\\sr\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: exceptiongroup in d:\\super resolution\\sr\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: jedi>=0.16 in d:\\super resolution\\sr\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in d:\\super resolution\\sr\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: typing-extensions in d:\\super resolution\\sr\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (4.12.2)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in d:\\super resolution\\sr\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in d:\\super resolution\\sr\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in d:\\super resolution\\sr\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in d:\\super resolution\\sr\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in d:\\super resolution\\sr\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in d:\\super resolution\\sr\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: executing>=1.2.0 in d:\\super resolution\\sr\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\super resolution\\sr\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Installing collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.3 jupyterlab-widgets-3.0.11 widgetsnbextension-4.0.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.2 is available.\n",
      "You should consider upgrading via the 'D:\\Super Resolution\\sr\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc7bd2615256463a960952c633f54b5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c5c48b2fb6415c8fb90818a937930a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'Mean' object has no attribute 'reset_states'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      3\u001b[0m PARAMS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(lrGenerator \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-4\u001b[39m, \n\u001b[0;32m      4\u001b[0m               lrDiscriminator \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-4\u001b[39m,\n\u001b[0;32m      5\u001b[0m               epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, \n\u001b[0;32m      6\u001b[0m               stepsPerEpoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m, \n\u001b[0;32m      7\u001b[0m               valSteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m      8\u001b[0m game \u001b[38;5;241m=\u001b[39m MinMaxGame(generator, discriminator, extractor)\n\u001b[1;32m----> 9\u001b[0m log, valLog \u001b[38;5;241m=\u001b[39m \u001b[43mgame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalData\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPARAMS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# ideally peak signal noise ratio(snRation or psnr) should reach ~22\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Super Resolution\\Utilities\\trainVal.py:169\u001b[0m, in \u001b[0;36mMinMaxGame.train\u001b[1;34m(self, trainData, valData, parameters)\u001b[0m\n\u001b[0;32m    160\u001b[0m             t\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch))\n\u001b[0;32m    161\u001b[0m             t\u001b[38;5;241m.\u001b[39mset_postfix(genLoss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalGenLossLog\u001b[38;5;241m.\u001b[39mresult()\u001b[38;5;241m.\u001b[39mnumpy(),\n\u001b[0;32m    162\u001b[0m                           genMSE\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalMseLog\u001b[38;5;241m.\u001b[39mresult()\u001b[38;5;241m.\u001b[39mnumpy(),\n\u001b[0;32m    163\u001b[0m                           genEntropy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalEntropyLog\u001b[38;5;241m.\u001b[39mresult()\u001b[38;5;241m.\u001b[39mnumpy(),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    166\u001b[0m                           disAcc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalAccLog\u001b[38;5;241m.\u001b[39mresult()\u001b[38;5;241m.\u001b[39mnumpy(),\n\u001b[0;32m    167\u001b[0m                           snRatio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalSnRatioLog\u001b[38;5;241m.\u001b[39mresult()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m--> 169\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_updateRecord\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalLog\n",
      "File \u001b[1;32mD:\\Super Resolution\\Utilities\\trainVal.py:100\u001b[0m, in \u001b[0;36mMinMaxGame._updateRecord\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccLog\u001b[38;5;241m.\u001b[39mresult()))\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# reset stats\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenLossLog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_states\u001b[49m()\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmseLog\u001b[38;5;241m.\u001b[39mreset_states()\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentropyLog\u001b[38;5;241m.\u001b[39mreset_states()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Mean' object has no attribute 'reset_states'"
     ]
    }
   ],
   "source": [
    "# training parameter. epoch is set to 1 for demonstration\n",
    "# please train the network utill it reaches snRatio ~= 22 \n",
    "PARAMS = dict(lrGenerator = 1e-4, \n",
    "              lrDiscriminator = 1e-4,\n",
    "              epochs = 1, \n",
    "              stepsPerEpoch = 500, \n",
    "              valSteps = 100)\n",
    "game = MinMaxGame(generator, discriminator, extractor)\n",
    "log, valLog = game.train(trainData, valData, PARAMS)\n",
    "# ideally peak signal noise ratio(snRation or psnr) should reach ~22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model\n",
    "Because I defined the model as inherited class of tf keras model, they cannot be safely serialized.  \n",
    "Therefore, please save the weights only and follow the instructions in tutorial 1 to reload the model  \n",
    "You can found my pretrained model in the *Pretrained* folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to function call (1991177027.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    generator.save_weights(YOUR_PATH), save_format='tf'\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m cannot assign to function call\n"
     ]
    }
   ],
   "source": [
    "generator.save_weights(D:\\\\Super Resolution\\\\dataset\\\\train\\\\low_res_resized), save_format='tf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
